17/08/21 20:39:06 INFO spark.SparkContext: Running Spark version 2.2.0
17/08/21 20:39:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/08/21 20:39:06 INFO spark.SparkContext: Submitted application: car statistics
17/08/21 20:39:06 INFO spark.SecurityManager: Changing view acls to: root
17/08/21 20:39:06 INFO spark.SecurityManager: Changing modify acls to: root
17/08/21 20:39:06 INFO spark.SecurityManager: Changing view acls groups to: 
17/08/21 20:39:06 INFO spark.SecurityManager: Changing modify acls groups to: 
17/08/21 20:39:06 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
17/08/21 20:39:07 INFO util.Utils: Successfully started service 'sparkDriver' on port 37351.
17/08/21 20:39:07 INFO spark.SparkEnv: Registering MapOutputTracker
17/08/21 20:39:07 INFO spark.SparkEnv: Registering BlockManagerMaster
17/08/21 20:39:07 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/08/21 20:39:07 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/08/21 20:39:07 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-79d0dacf-27dc-4cff-a172-6958f874a84e
17/08/21 20:39:07 INFO memory.MemoryStore: MemoryStore started with capacity 2.5 GB
17/08/21 20:39:07 INFO spark.SparkEnv: Registering OutputCommitCoordinator
17/08/21 20:39:07 INFO util.log: Logging initialized @1384ms
17/08/21 20:39:07 INFO server.Server: jetty-9.3.z-SNAPSHOT
17/08/21 20:39:07 INFO server.Server: Started @1443ms
17/08/21 20:39:07 INFO server.AbstractConnector: Started ServerConnector@7f3dcd7c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
17/08/21 20:39:07 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3113a37{/jobs,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@49a64d82{/jobs/json,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@66d23e4a{/jobs/job,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@52c8295b{/jobs/job/json,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@77b21474{/stages,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@41c07648{/stages/json,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@781e7326{/stages/stage,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@324dcd31{/stages/stage/json,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@72bca894{/stages/pool,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1fc793c2{/stages/pool/json,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@329a1243{/storage,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2d35442b{/storage/json,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4593ff34{/storage/rdd,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@30c0ccff{/storage/rdd/json,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@22db8f4{/environment,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1d572e62{/environment/json,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@46cf05f7{/executors,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7cd1ac19{/executors/json,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3caa4757{/executors/threadDump,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1804f60d{/executors/threadDump/json,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@547e29a4{/static,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@733037{/,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@320e400{/api,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6ebd78d1{/jobs/job/kill,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4d157787{/stages/stage/kill,null,AVAILABLE,@Spark}
17/08/21 20:39:07 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.10.60.204:4040
17/08/21 20:39:07 INFO spark.SparkContext: Added JAR file:/root/workdir/statisticscars-1.0-SNAPSHOT-jar-with-dependencies.jar at spark://10.10.60.204:37351/jars/statisticscars-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1503319147429
17/08/21 20:39:08 INFO yarn.Client: Requesting a new application from cluster with 2 NodeManagers
17/08/21 20:39:08 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (4096 MB per container)
17/08/21 20:39:08 ERROR spark.SparkContext: Error initializing SparkContext.
java.lang.IllegalArgumentException: Required executor memory (20480+2048 MB) is above the max threshold (4096 MB) of this cluster! Please check the values of 'yarn.scheduler.maximum-allocation-mb' and/or 'yarn.nodemanager.resource.memory-mb'.
	at org.apache.spark.deploy.yarn.Client.verifyClusterResources(Client.scala:302)
	at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:166)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:56)
	at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:173)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:509)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2509)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:909)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:901)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
	at com.hx.bigdata.AppCore$.main(AppCore.scala:27)
	at com.hx.bigdata.AppCore.main(AppCore.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
17/08/21 20:39:08 INFO server.AbstractConnector: Stopped Spark@7f3dcd7c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
17/08/21 20:39:08 INFO ui.SparkUI: Stopped Spark web UI at http://10.10.60.204:4040
17/08/21 20:39:08 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!
17/08/21 20:39:08 INFO cluster.YarnClientSchedulerBackend: Stopped
17/08/21 20:39:08 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/08/21 20:39:08 INFO memory.MemoryStore: MemoryStore cleared
17/08/21 20:39:08 INFO storage.BlockManager: BlockManager stopped
17/08/21 20:39:08 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
17/08/21 20:39:08 WARN metrics.MetricsSystem: Stopping a MetricsSystem that is not running
17/08/21 20:39:08 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/08/21 20:39:08 INFO spark.SparkContext: Successfully stopped SparkContext
Exception in thread "main" java.lang.IllegalArgumentException: Required executor memory (20480+2048 MB) is above the max threshold (4096 MB) of this cluster! Please check the values of 'yarn.scheduler.maximum-allocation-mb' and/or 'yarn.nodemanager.resource.memory-mb'.
	at org.apache.spark.deploy.yarn.Client.verifyClusterResources(Client.scala:302)
	at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:166)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:56)
	at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:173)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:509)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2509)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:909)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:901)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
	at com.hx.bigdata.AppCore$.main(AppCore.scala:27)
	at com.hx.bigdata.AppCore.main(AppCore.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
17/08/21 20:39:08 INFO util.ShutdownHookManager: Shutdown hook called
17/08/21 20:39:08 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-aca8115f-9e96-4aa8-af5a-2bac750d6a9a
